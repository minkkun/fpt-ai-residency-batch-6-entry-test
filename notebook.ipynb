{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T21:06:14.423535Z",
     "start_time": "2025-03-28T21:06:14.405851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20833c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f10d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Optimizing by using GPU if available\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "accelerator = Accelerator()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b6405e740078c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T21:06:14.471397Z",
     "start_time": "2025-03-28T21:06:14.425515Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/b6_train_data.csv\")\n",
    "# turn into a Python list for tokenization\n",
    "df[\"choices\"] = df['choices'].apply(eval)\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09409401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForMultipleChoice(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, AutoTokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Wrap with `accelerate`\n",
    "model = accelerator.prepare(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1102e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_to_number = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "\n",
    "\n",
    "def get_number(ans):\n",
    "    try:\n",
    "        last_word = ans.split()[-1]  # Get the last word\n",
    "        # Return mapped value or -1 if not found\n",
    "        return letter_to_number.get(last_word, -1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing answer '{ans}': {e}\")\n",
    "        return -1  # Fallback value\n",
    "\n",
    "\n",
    "def preprocess(examples):\n",
    "    # Ensure choices are lists and pad to 4 choices\n",
    "    examples[\"choices\"] = [\n",
    "        choice + [\"\"] * (4 - len(choice)) if len(choice) < 4 else choice[:4]\n",
    "        for choice in examples[\"choices\"]\n",
    "    ]\n",
    "\n",
    "    # Number of choices per question (always 4 now)\n",
    "    choice_lens = [4] * len(examples[\"choices\"])\n",
    "\n",
    "    # Expand questions to match the number of choices (4 per question)\n",
    "    questions = [q for q_list in [[question] *\n",
    "                                  4 for question in examples['question']] for q in q_list]\n",
    "    choices = sum(examples[\"choices\"], [])  # Flatten choices\n",
    "\n",
    "    # Convert labels\n",
    "    labels = [get_number(label) for label in examples['answer']]\n",
    "\n",
    "    # Tokenize questions and choices as independent pairs\n",
    "    tokenized_examples = tokenizer(\n",
    "        list(zip(questions, choices)), truncation=True, padding=\"max_length\", max_length=256\n",
    "    )\n",
    "\n",
    "    # Reshape data: Group every 4 choices together (for each question)\n",
    "    reshaped_dict = {k: [] for k in tokenized_examples.keys()}\n",
    "    start = 0\n",
    "    for _ in range(len(examples[\"question\"])):  # Iterate per question\n",
    "        for k in tokenized_examples.keys():\n",
    "            reshaped_dict[k].append(tokenized_examples[k][start: start + 4])\n",
    "        start += 4\n",
    "\n",
    "    # Ensure labels match the 4-choice structure\n",
    "    reshaped_dict['labels'] = labels\n",
    "\n",
    "    return reshaped_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ae4533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90dc613b85d4c23ba5ecce2bbb0d30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3963 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n",
      "Error processing answer 'None': 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "tokenized_data = dataset.map(\n",
    "    preprocess, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1dec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : what value does the variable z have after all of the code above executes? int x ; int y ; int z ; x = 3 ; y = 4 ; z = + + x * y + + ; 9\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(\n",
    "    tokenized_data[9][\"input_ids\"][0], skip_special_tokens=True)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949e4d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504cec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForMultipleChoice\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Initialize collator\n",
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f89f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "# Split your dataset into train and evaluation sets\n",
    "\n",
    "train_test_split = tokenized_data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbde189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9499c59789ed4174bf0f1b70bbe0f007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19fce7774cf4e9980d39f5124d5c5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.filter(\n",
    "    lambda example: example[\"labels\"] != -1)\n",
    "eval_dataset = eval_dataset.filter(\n",
    "    lambda example: example[\"labels\"] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5bf2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from evaluate import load\n",
    "\n",
    "# Load a metric (F1-score in this case)\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "# Define a custom compute_metrics function\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84066110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" not in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa43dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7693c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "log_dir = \"./logs\"\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaf8208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "torch.mps.empty_cache()\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mcq_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    max_grad_norm=1.0,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=1e-5,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    load_best_model_at_end=True,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    dataloader_pin_memory=False,       # Disable for MPS\n",
    "    dataloader_num_workers=0,          # Must be 0 on MPS\n",
    "    torch_compile=False\n",
    ")\n",
    "\n",
    "\n",
    "class DebugTrainer(Trainer):\n",
    "    def training_step(self, model, inputs, nums_items_in_batch):\n",
    "        outputs = model(**inputs)\n",
    "        print(\"Loss:\", outputs.loss)\n",
    "        return outputs.loss\n",
    "\n",
    "\n",
    "# Create the Trainer instance\n",
    "trainer = DebugTrainer(\n",
    "    model=model,                        # Pre-trained BERT model\n",
    "    args=training_args,                 # Training arguments\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,        # Efficient batching\n",
    "    compute_metrics=compute_metrics     # Custom metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74ff7dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(1.3802, device='mps:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2130' max='3152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2130/3152 03:21 < 01:36, 10.54 it/s, Epoch 1.35/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.374700</td>\n",
       "      <td>1.385725</td>\n",
       "      <td>0.278834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(1.3916, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3698, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3803, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3505, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4742, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3869, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4335, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4025, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3944, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3131, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3758, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4933, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3414, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3630, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4157, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3520, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4248, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3098, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3572, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3515, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3751, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4290, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3915, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3887, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3403, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3805, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4232, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3981, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3470, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3442, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3779, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3652, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3614, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3721, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4752, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3831, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3394, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3278, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3350, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3511, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3382, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4062, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4415, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2984, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4029, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3564, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3838, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4278, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4346, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3627, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3756, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3777, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4270, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3779, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4329, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3838, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4086, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3768, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4179, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4117, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4382, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3932, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4431, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4438, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3727, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3902, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3972, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4295, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4157, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4216, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3880, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3616, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3798, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4653, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3732, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3772, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4428, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3921, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3567, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4897, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3317, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3604, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3692, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3973, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4118, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3786, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3571, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3643, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3761, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3821, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3476, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3361, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3988, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3646, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2942, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3498, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3949, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3817, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4042, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3317, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3995, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3518, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4097, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4037, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4038, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3730, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3292, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4059, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3154, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3975, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3680, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4180, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4141, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3753, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3792, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3840, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4446, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3725, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4004, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3303, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4239, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4563, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4236, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4105, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3780, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3227, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3286, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4324, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3237, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3408, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3339, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4451, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3963, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3745, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4078, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3832, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3886, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4117, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3715, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4092, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3815, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3807, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4159, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3428, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3613, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4028, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3532, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4230, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3817, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3500, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4578, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4129, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.5103, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3638, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3554, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3551, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4074, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3917, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3894, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3347, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4281, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3338, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3621, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4360, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4140, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4298, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3249, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3693, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3533, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3811, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3754, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3627, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3740, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3509, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4275, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3558, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3774, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4249, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3707, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3733, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3809, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4024, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3598, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3687, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3932, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4401, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4089, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4272, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3948, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3609, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3629, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3961, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4018, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4379, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4165, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4051, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3991, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3499, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4171, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3597, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4207, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4234, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3784, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3804, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3369, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3957, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3947, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4035, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4142, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4631, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4395, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4062, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3347, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3782, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4450, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4028, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3678, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4214, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4685, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3517, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3594, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3881, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4392, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3651, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3624, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4305, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3934, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3326, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3807, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3812, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3702, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4138, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4249, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3746, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3657, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3407, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4313, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3782, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3811, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4410, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3630, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3970, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4232, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3942, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3959, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3796, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3622, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3725, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4097, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3049, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3810, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3900, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4297, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3708, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4496, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4225, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4038, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4221, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3561, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3971, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4297, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4075, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4312, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3657, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3571, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3899, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4242, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3992, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3820, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3651, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4272, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3990, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3368, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4147, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3885, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4229, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3823, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4368, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3654, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3382, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3754, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3586, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4153, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3437, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4219, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3827, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4040, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3795, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4079, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3901, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3807, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4159, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4356, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4135, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3675, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3374, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3590, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3578, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3940, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3666, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3549, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4521, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4292, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4565, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3986, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3957, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3601, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3463, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4009, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4464, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3486, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3453, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3945, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3688, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3751, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3520, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3040, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3664, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3612, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3812, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4261, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3559, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4112, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3678, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4066, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3987, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4180, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3958, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3580, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3483, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3919, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3819, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3966, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3885, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4346, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3890, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4535, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4415, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4175, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3600, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4446, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4112, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3792, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3739, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3935, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3698, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3331, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3669, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3662, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4122, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4082, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4099, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4031, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3978, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3803, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3617, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4037, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3983, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3797, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3731, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3230, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3869, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3747, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3965, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3010, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4038, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3779, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3689, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3724, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3568, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4140, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4347, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4203, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4091, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3996, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4055, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3954, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3815, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3939, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3469, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3630, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3906, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3829, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4238, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3652, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4508, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4234, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4217, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3998, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4337, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4059, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4108, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3304, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3940, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4354, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4044, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3810, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3232, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3451, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4688, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3892, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4007, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3602, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4378, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3574, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4261, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3915, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3789, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3950, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3739, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3901, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3942, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3918, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4164, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4218, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4421, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4321, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4057, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3765, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4175, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3840, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3766, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3772, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4050, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4181, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3699, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4351, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4130, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4190, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4270, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3650, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3570, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3934, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3774, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3488, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4365, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3782, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4150, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4329, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3809, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3298, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4340, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4277, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3689, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3952, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3345, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3223, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4207, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3732, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3360, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4201, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3654, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3764, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4087, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3371, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4052, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3960, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4019, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4048, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3966, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3436, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3737, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3290, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3965, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4189, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3712, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4096, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3727, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4261, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3972, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4444, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3809, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3166, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4064, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3313, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3898, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3725, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3697, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4219, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4103, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4103, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4251, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3898, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3877, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3645, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4104, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4031, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3462, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3608, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3625, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4458, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3381, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3547, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4404, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4033, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4169, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4269, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3886, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4337, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3890, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3700, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4053, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4437, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3874, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3773, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3828, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4259, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3623, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3645, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3465, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4542, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3760, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3623, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3942, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3418, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3703, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3780, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3926, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3712, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3590, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3359, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3829, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4015, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3670, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3578, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3661, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3838, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3742, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3377, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4388, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3752, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3524, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3997, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3816, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3405, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3606, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3807, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4149, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3574, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4303, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3686, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3875, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4078, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3771, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3732, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4275, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3268, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4211, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3380, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3950, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4159, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3547, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4715, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3813, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3964, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3942, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3705, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4036, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3418, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3733, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3718, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4027, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4648, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4091, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4290, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3794, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4012, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4277, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2992, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3709, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3782, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3966, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3567, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.5173, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3497, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3504, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3691, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3633, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3757, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4369, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4467, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4024, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4373, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4156, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4314, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3503, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3718, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3639, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4274, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4067, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3662, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3718, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4140, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3243, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4378, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3846, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3415, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3674, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3512, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4158, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3908, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4007, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3812, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3510, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3341, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3342, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4603, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4350, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3870, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3671, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3571, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4092, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3541, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3242, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3449, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4389, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3586, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3464, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4335, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3623, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3226, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4374, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3789, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4766, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3423, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4372, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3905, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3366, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3846, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3396, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4090, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3410, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4340, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4697, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3653, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3416, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3665, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3817, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3477, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4283, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3677, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3442, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3818, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3905, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4100, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4437, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3698, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4180, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4224, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3939, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4096, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4649, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3363, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3497, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3688, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4146, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4011, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3516, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3989, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3899, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3611, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3735, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4032, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4197, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3145, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3798, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3914, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4361, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4389, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2968, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3973, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3829, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4004, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4009, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3535, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3440, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3705, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3653, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3410, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4002, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3374, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3296, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4303, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4443, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4198, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3457, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4010, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3572, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3540, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4299, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3959, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4013, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3439, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3968, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3514, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4257, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3708, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3451, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4015, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3509, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3898, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4066, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4228, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4000, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3729, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4571, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4354, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3470, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3795, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3913, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3660, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4214, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3876, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4233, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3336, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3323, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3607, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3894, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4566, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4343, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4246, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3367, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3968, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4054, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3866, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3801, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3604, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3484, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3963, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3468, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3928, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4188, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3756, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3819, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4476, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4360, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3556, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4496, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4004, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3769, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4241, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3558, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4393, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3593, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3717, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3807, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3655, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2940, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4045, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3459, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3642, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4087, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3428, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3421, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4286, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4046, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3572, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3747, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3640, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4018, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3823, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4094, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3891, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4157, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3866, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4259, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3935, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3257, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3700, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3911, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3469, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3567, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3574, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4243, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3599, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3667, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3893, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3558, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4360, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3622, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3599, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4057, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4046, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4200, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3906, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3657, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3624, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3827, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3612, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3465, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4011, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3794, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3474, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3711, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3281, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3944, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3599, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3042, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3981, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3985, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4036, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3133, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3222, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3619, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3660, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4406, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3687, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3929, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3371, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4162, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3712, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3784, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4069, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4161, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3457, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4866, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3600, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4491, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3380, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3763, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3385, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3835, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4147, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3741, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3433, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4315, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3259, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3910, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3205, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3268, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4008, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3621, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4349, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3537, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3620, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3816, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3473, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3770, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4053, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3911, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4266, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3469, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4006, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3831, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3660, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3304, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3631, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3916, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3629, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3796, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3788, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3898, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3329, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3796, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3892, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3965, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3939, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3572, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3839, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4002, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3204, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3255, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4251, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3810, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4157, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3327, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4377, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3961, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3840, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3149, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3606, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4215, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3634, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4035, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4264, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4065, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4377, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4112, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3439, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4216, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3368, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4085, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3925, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3792, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3734, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4149, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3104, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4178, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4090, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4635, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3610, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4079, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3714, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3368, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4120, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4369, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4175, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3927, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3748, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3607, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4033, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4095, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4176, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3304, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3907, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3570, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3211, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3878, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3978, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3771, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3846, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4397, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3761, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4446, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3796, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4446, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3663, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3390, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3797, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3324, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3970, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3940, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4118, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3919, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3977, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3195, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4131, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3432, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4102, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3605, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3371, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3928, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4235, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3701, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3714, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4341, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4088, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3746, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4170, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3466, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3864, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4435, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4003, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3952, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3494, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4145, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3903, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4159, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3725, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3314, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3690, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3736, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4312, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4077, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3438, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3474, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4234, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3688, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3503, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3305, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4329, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3722, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4091, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4118, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3310, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3640, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4183, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3957, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3766, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3776, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3955, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4101, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3944, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4443, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3878, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4841, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4164, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4214, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4021, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3665, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3687, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3484, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3686, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3719, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4465, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3359, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4436, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3840, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4083, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4811, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3800, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4197, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3386, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3451, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4104, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4494, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3846, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4415, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4257, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3668, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4183, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3491, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4249, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4153, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3591, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3902, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4035, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4581, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3984, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3744, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3338, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4021, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3551, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3679, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3798, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4211, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3369, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4473, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4209, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4115, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4140, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3793, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4220, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4165, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3673, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3697, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3945, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3627, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4537, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4193, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4102, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3509, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4408, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4202, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3618, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3991, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3757, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3915, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3335, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3820, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3587, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3408, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4240, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3402, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4405, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3799, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4009, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4122, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3856, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4175, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3256, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3727, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3113, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4478, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3963, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3072, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3485, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3499, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3608, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3205, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4048, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3489, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4415, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3767, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3735, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4487, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4063, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4451, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3930, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3708, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4312, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4046, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3627, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4157, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3673, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4357, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3678, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4377, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4209, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4583, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3588, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3911, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3897, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3562, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4013, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3593, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3479, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3749, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3891, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3982, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3081, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4580, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3220, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4147, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3799, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3683, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4244, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4202, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3426, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3700, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3962, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4059, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4303, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4024, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3609, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3294, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3381, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4432, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3719, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4666, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3925, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4591, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4345, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3414, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3547, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3698, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4152, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3559, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4191, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3731, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4600, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4587, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3711, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3813, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3613, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3773, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3006, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2971, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4444, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3665, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4168, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3553, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3451, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3196, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3603, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4086, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3999, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3672, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3633, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4086, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3542, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4097, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4151, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3961, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3818, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4183, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4468, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3569, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4137, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4686, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4117, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3693, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3797, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3664, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3594, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4236, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4018, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3789, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3436, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4143, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3442, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3552, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3951, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3526, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4105, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4494, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3518, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3808, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3958, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3589, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3606, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3431, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3778, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3890, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3945, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4143, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4001, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3749, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4249, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4138, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4246, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3303, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4580, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3325, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4150, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3499, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4301, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3608, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3882, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3914, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3792, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3651, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3722, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3748, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3609, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3341, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4225, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3261, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3934, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4751, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3830, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3894, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4185, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3501, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4448, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3586, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4024, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3439, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3630, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3796, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3808, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3607, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3647, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3863, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3723, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4055, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3466, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4276, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4383, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3940, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4276, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4044, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3744, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4347, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4423, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3442, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3944, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3933, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4222, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3688, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4090, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4209, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3126, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3827, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3762, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3701, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3750, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3437, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4591, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4571, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3927, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3735, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4035, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3642, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4086, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3781, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4303, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3276, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3766, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3771, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3898, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4274, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3946, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3887, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4174, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3961, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3082, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3912, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3760, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3678, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4078, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4366, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3680, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3647, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3459, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4222, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3965, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3842, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4079, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3974, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3754, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3422, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3723, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3706, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4156, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4351, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4157, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4235, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3444, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3810, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4099, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3960, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3680, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4034, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3511, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3906, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3732, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4229, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3758, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3414, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4088, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4231, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3740, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3706, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3448, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4082, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3718, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3780, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4741, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4020, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4045, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3358, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3539, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3976, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4461, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3270, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4316, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4320, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4190, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4144, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4265, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3778, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4224, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3976, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3819, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4241, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3683, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3045, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3486, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4224, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3979, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3657, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4284, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4034, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3910, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3352, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4390, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3620, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4066, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3720, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4243, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4636, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3614, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3923, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4327, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4011, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4485, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4015, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3793, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3556, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3327, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4183, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4023, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3311, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3816, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3957, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3084, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4085, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4294, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3528, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4587, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3604, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3597, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4069, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3307, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3738, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3605, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3282, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3780, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3719, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3627, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4105, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3497, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3174, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4113, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3576, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4088, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3920, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4424, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4144, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3424, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4038, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4215, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3912, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3141, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3583, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4213, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3392, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3530, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3406, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4038, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3968, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3448, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3124, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3780, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3715, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3911, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3476, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3960, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4044, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3920, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4053, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.5109, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3747, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3672, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3918, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4010, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3626, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3587, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4138, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4667, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3772, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3426, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3484, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4024, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3926, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3999, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3965, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3894, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4442, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4059, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4279, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3321, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3832, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4804, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4103, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3793, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4181, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3560, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3720, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3766, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4055, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4169, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4211, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3474, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3220, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3684, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3755, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3761, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3636, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4806, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3433, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3794, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3633, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3789, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3331, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3809, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3336, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3757, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4214, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4181, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4319, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4669, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3856, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4057, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3246, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4378, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3540, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4157, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4001, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4232, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4259, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3146, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3551, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3893, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4415, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3795, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4049, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3753, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3767, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4210, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3970, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3706, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4225, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4202, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4441, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3987, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4124, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3801, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3154, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3661, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3470, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4129, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3462, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3748, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3411, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4377, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3730, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3812, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4091, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3540, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3638, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3679, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.2925, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4522, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3792, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4288, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3708, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3758, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4166, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4538, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3707, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4762, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3268, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3722, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3735, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3399, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3888, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3251, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3408, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3609, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4410, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4301, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3748, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3978, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4272, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4556, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3778, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3797, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3856, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3904, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3835, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3894, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3950, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3824, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3881, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3788, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3812, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3846, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3806, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3864, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3916, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3817, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3776, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3821, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3855, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3824, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3821, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3822, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3804, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3816, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3826, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3838, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3827, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3870, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4010, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3828, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3823, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4050, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3874, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3832, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3892, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3893, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3886, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3813, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3935, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3829, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3869, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3874, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3798, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3891, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3846, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3842, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3906, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3880, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3888, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3876, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3811, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3902, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3874, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3880, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3886, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3835, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3831, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3781, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3908, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3790, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3755, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3876, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3851, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3826, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3896, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3933, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3880, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3837, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3888, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3875, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3815, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3892, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3863, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3890, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3877, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3826, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3893, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3939, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3922, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3944, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3851, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3806, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3837, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3773, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3868, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3892, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3805, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3799, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3829, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3889, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3829, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3948, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3830, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3891, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3878, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3876, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3828, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3810, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3916, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3866, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3910, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3780, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3825, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3834, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3825, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3804, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3827, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3863, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3856, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3834, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3891, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3937, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3912, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3876, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3819, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3718, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3771, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3900, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3890, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3870, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3834, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3863, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3887, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3825, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3843, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3855, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3868, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3866, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3829, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3880, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3798, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3961, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3819, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3949, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3896, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3838, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3863, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3877, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3851, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3843, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3799, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3870, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3886, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3913, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3877, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3882, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3800, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3843, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3851, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3832, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3882, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3882, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3863, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3877, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3851, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3905, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3851, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3995, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3798, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3882, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3885, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3851, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3832, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3866, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3901, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3870, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3806, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3908, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3798, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3811, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3834, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3834, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3840, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3810, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3906, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3901, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3856, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3856, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3857, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3863, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3881, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3877, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3874, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3823, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3851, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3938, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3802, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3881, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3967, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3874, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3831, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3902, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3869, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3828, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3824, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3886, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3839, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3796, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3931, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3807, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3831, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3834, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3868, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3842, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3870, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3839, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3831, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3878, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3830, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3815, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3870, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3888, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3855, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3871, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3881, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3877, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3880, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3892, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3841, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3830, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3809, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3893, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3810, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3888, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3820, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3887, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3885, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3894, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3903, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3966, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3875, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3908, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3803, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3803, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3907, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3923, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3910, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3902, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3876, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3907, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3828, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3842, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3839, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3813, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3889, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3786, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3800, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3820, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3919, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3877, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3824, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3863, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3850, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3842, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3846, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3855, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3843, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3780, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3828, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3887, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3891, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3814, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3910, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3882, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3814, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3806, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3894, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3874, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3814, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3921, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3854, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3819, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3814, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3813, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.4028, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3876, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3833, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3892, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3864, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3925, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3916, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3826, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3817, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3848, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3874, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3858, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3832, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3811, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3824, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3869, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3864, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3844, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3838, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3856, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3855, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3883, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3853, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3807, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3866, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3847, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3987, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3830, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3869, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3831, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3948, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3845, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3869, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3887, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3886, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3873, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3825, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3861, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3855, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3846, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3910, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3864, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3852, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3879, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3828, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3864, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3834, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3882, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3795, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3868, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3862, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3895, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3936, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3838, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3790, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3865, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3859, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3885, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3765, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3904, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3864, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3890, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3829, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3872, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3889, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3839, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3886, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3849, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3828, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3836, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3860, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3923, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Loss: tensor(1.3884, device='mps:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Start the training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2bb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15cc8f3",
   "metadata": {},
   "source": [
    "# Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df = pd.read_csv(\"./data/b6_test_data.csv\")\n",
    "test_df[\"choices\"] = test_df['choices'].apply(eval)\n",
    "fpttest_data = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_predict(examples):\n",
    "    # Ensure choices are lists and pad to 4 choices\n",
    "    examples[\"choices\"] = [\n",
    "        choice + [\"\"] * (4 - len(choice)) if len(choice) < 4 else choice[:4]\n",
    "        for choice in examples[\"choices\"]\n",
    "    ]\n",
    "\n",
    "    # Expand questions to match the number of choices (4 per question)\n",
    "    questions = [q for q_list in [[question] *\n",
    "                                  4 for question in examples['question']] for q in q_list]\n",
    "    choices = sum(examples[\"choices\"], [])  # Flatten choices\n",
    "\n",
    "    # Tokenize questions and choices as independent pairs\n",
    "    tokenized_examples = tokenizer(\n",
    "        list(zip(questions, choices)), truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Reshape data: Group every 4 choices together (for each question)\n",
    "    reshaped_dict = {k: [] for k in tokenized_examples.keys()}\n",
    "    start = 0\n",
    "    for _ in range(len(examples[\"question\"])):  # Iterate per question\n",
    "        for k in tokenized_examples.keys():\n",
    "            reshaped_dict[k].append(tokenized_examples[k][start: start + 4])\n",
    "        start += 4\n",
    "\n",
    "    return reshaped_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e7604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce088f4dcb5d4b4d9d9fff0383cf63aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1253 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_id': 'k10171', 'question': 'Question: What will be output of the following c code?\\n#include<stdio.h>\\nint main()\\n{\\n    int a= sizeof(signed) +sizeof(unsigned);\\n    int b=sizeof(const)+sizeof(volatile);\\n    printf(\"%d\",a+++b);\\n    return 0;\\n}', 'choices': ['10', '9', '8', 'Error'], 'input_ids': [[101, 3160, 1024, 2054, 2097, 2022, 6434, 1997, 1996, 2206, 1039, 3642, 1029, 1001, 2421, 1026, 2358, 20617, 1012, 1044, 1028, 20014, 2364, 1006, 1007, 1063, 20014, 1037, 1027, 2946, 11253, 1006, 2772, 1007, 1009, 2946, 11253, 1006, 27121, 1007, 1025, 20014, 1038, 1027, 2946, 11253, 1006, 9530, 3367, 1007, 1009, 2946, 11253, 1006, 20606, 1007, 1025, 6140, 2546, 1006, 1000, 1003, 1040, 1000, 1010, 1037, 1009, 1009, 1009, 1038, 1007, 1025, 2709, 1014, 1025, 1065, 102, 2184, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3160, 1024, 2054, 2097, 2022, 6434, 1997, 1996, 2206, 1039, 3642, 1029, 1001, 2421, 1026, 2358, 20617, 1012, 1044, 1028, 20014, 2364, 1006, 1007, 1063, 20014, 1037, 1027, 2946, 11253, 1006, 2772, 1007, 1009, 2946, 11253, 1006, 27121, 1007, 1025, 20014, 1038, 1027, 2946, 11253, 1006, 9530, 3367, 1007, 1009, 2946, 11253, 1006, 20606, 1007, 1025, 6140, 2546, 1006, 1000, 1003, 1040, 1000, 1010, 1037, 1009, 1009, 1009, 1038, 1007, 1025, 2709, 1014, 1025, 1065, 102, 1023, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3160, 1024, 2054, 2097, 2022, 6434, 1997, 1996, 2206, 1039, 3642, 1029, 1001, 2421, 1026, 2358, 20617, 1012, 1044, 1028, 20014, 2364, 1006, 1007, 1063, 20014, 1037, 1027, 2946, 11253, 1006, 2772, 1007, 1009, 2946, 11253, 1006, 27121, 1007, 1025, 20014, 1038, 1027, 2946, 11253, 1006, 9530, 3367, 1007, 1009, 2946, 11253, 1006, 20606, 1007, 1025, 6140, 2546, 1006, 1000, 1003, 1040, 1000, 1010, 1037, 1009, 1009, 1009, 1038, 1007, 1025, 2709, 1014, 1025, 1065, 102, 1022, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3160, 1024, 2054, 2097, 2022, 6434, 1997, 1996, 2206, 1039, 3642, 1029, 1001, 2421, 1026, 2358, 20617, 1012, 1044, 1028, 20014, 2364, 1006, 1007, 1063, 20014, 1037, 1027, 2946, 11253, 1006, 2772, 1007, 1009, 2946, 11253, 1006, 27121, 1007, 1025, 20014, 1038, 1027, 2946, 11253, 1006, 9530, 3367, 1007, 1009, 2946, 11253, 1006, 20606, 1007, 1025, 6140, 2546, 1006, 1000, 1003, 1040, 1000, 1010, 1037, 1009, 1009, 1009, 1038, 1007, 1025, 2709, 1014, 1025, 1065, 102, 7561, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_fpt = fpttest_data.map(\n",
    "    preprocess_predict, batched=True, batch_size=8, load_from_cache_file=False)\n",
    "\n",
    "print(tokenized_fpt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba7b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0842, -0.0740, -0.0724, -0.0502]], device='mps:0')\n",
      "['D']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMultipleChoice, AutoTokenizer\n",
    "\n",
    "# Set device to MPS or CUDA (if available)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available(\n",
    ") else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained BERT model for multiple-choice tasks (no fine-tuning)\n",
    "path = \"./mcq_model/checkpoint-394/\"\n",
    "model = AutoModelForMultipleChoice.from_pretrained(path)\n",
    "model.to(device)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "\n",
    "# Define number to letter mapping\n",
    "number_to_letter = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "\n",
    "\n",
    "def predict_single_token(tokenized_data):\n",
    "    \"\"\"\n",
    "    Predicts the best answer choice for a given multiple-choice question.\n",
    "    \"\"\"\n",
    "    input_ids = tokenized_data['input_ids']\n",
    "    attention_mask = tokenized_data['attention_mask']\n",
    "\n",
    "    # Ensure the input_ids and attention_mask have shape (batch_size, num_choices, sequence_length)\n",
    "    input_ids = input_ids.to(device)  # Move to device (MPS or GPU)\n",
    "    attention_mask = attention_mask.to(device)  # Same for attention_mask\n",
    "\n",
    "    # Perform prediction without calculating gradients (in inference mode)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Get the logits (predicted scores) for each choice\n",
    "    logits = outputs.logits  # Shape: (batch_size, num_choices)\n",
    "    print(logits)\n",
    "\n",
    "    # Get the predicted index (which choice has the highest score)\n",
    "    predictions = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "    # Map the predicted index to the corresponding letter (A, B, C, D)\n",
    "    predicted_answers = [number_to_letter[prediction]\n",
    "                         for prediction in predictions]\n",
    "\n",
    "    return predicted_answers\n",
    "\n",
    "\n",
    "# Example of a single tokenized input (representing a single multiple-choice question)\n",
    "question = \"What is the capital of United States?\"\n",
    "choices = [\"Berlin\", \"Madrid\", \"Hanoi\", \"DC\"]\n",
    "\n",
    "# Tokenize the question and choices using the tokenizer, ensuring consistent padding\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "for choice in choices:\n",
    "    # Tokenize the question and choice pair\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        question, choice,  # Question and each choice\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',  # Ensure consistent padding\n",
    "        truncation=True,\n",
    "        max_length=512,  # Adjust the max_length if necessary\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Append the tokenized inputs\n",
    "    input_ids.append(encoded['input_ids'])\n",
    "    attention_mask.append(encoded['attention_mask'])\n",
    "\n",
    "# Stack all the choices to create the batch\n",
    "input_ids = torch.cat(input_ids, dim=0).to(\n",
    "    device)  # Shape: (num_choices, sequence_length)\n",
    "attention_mask = torch.cat(attention_mask, dim=0).to(\n",
    "    device)  # Same shape as input_ids\n",
    "\n",
    "\n",
    "# Prepare the inputs as a dictionary\n",
    "tokenized_data = {\n",
    "    'input_ids': input_ids.unsqueeze(0),  # Add batch dimension\n",
    "    'attention_mask': attention_mask.unsqueeze(0),  # Add batch dimension\n",
    "}\n",
    "\n",
    "# Run the prediction on the single tokenized example\n",
    "predictions = predict_single_token(tokenized_data)\n",
    "print(predictions)  # Output: ['A', 'B', etc.]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
